{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from custom_libraries.miscellaneous import *\n",
    "from custom_libraries.image_dataset import *\n",
    "from custom_libraries.aktree import *\n",
    "import numpy as np\n",
    "import gc\n",
    "from os.path import exists"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: results/aktree_history_20_testLearningRate.npy\n",
      "Dataset: mnist / Pair: 3-5\n",
      "1-tree\n",
      "Trial 1\n",
      "Depth of the tree:  13\n",
      "Epoch 1/2000\n",
      "39/39 [==============================] - 24s 53ms/step - loss: 426.9753 - binary_crossentropy: 426.9753 - acc: 0.4813 - val_loss: 0.9724 - val_binary_crossentropy: 0.9724 - val_acc: 0.3756\n",
      "Epoch 2/2000\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.9410 - binary_crossentropy: 0.9410 - acc: 0.4008 - val_loss: 0.8570 - val_binary_crossentropy: 0.8570 - val_acc: 0.4143\n",
      "Epoch 3/2000\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.8031 - binary_crossentropy: 0.8031 - acc: 0.4991 - val_loss: 0.7818 - val_binary_crossentropy: 0.7818 - val_acc: 0.4991\n",
      "Epoch 4/2000\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.7490 - binary_crossentropy: 0.7490 - acc: 0.5141 - val_loss: 0.7209 - val_binary_crossentropy: 0.7209 - val_acc: 0.5586\n",
      "Epoch 5/2000\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.7113 - binary_crossentropy: 0.7113 - acc: 0.5591 - val_loss: 0.7055 - val_binary_crossentropy: 0.7055 - val_acc: 0.5661\n",
      "Epoch 6/2000\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.6991 - binary_crossentropy: 0.6991 - acc: 0.5682 - val_loss: 0.6976 - val_binary_crossentropy: 0.6976 - val_acc: 0.5713\n",
      "Epoch 7/2000\n",
      "39/39 [==============================] - 1s 25ms/step - loss: 0.6919 - binary_crossentropy: 0.6919 - acc: 0.5723 - val_loss: 0.6916 - val_binary_crossentropy: 0.6916 - val_acc: 0.5753\n",
      "Epoch 8/2000\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.6868 - binary_crossentropy: 0.6868 - acc: 0.5768 - val_loss: 0.6873 - val_binary_crossentropy: 0.6873 - val_acc: 0.5805\n",
      "Epoch 9/2000\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.6827 - binary_crossentropy: 0.6827 - acc: 0.5804 - val_loss: 0.6710 - val_binary_crossentropy: 0.6710 - val_acc: 0.5851\n",
      "Epoch 10/2000\n",
      "39/39 [==============================] - 1s 27ms/step - loss: 0.6204 - binary_crossentropy: 0.6204 - acc: 0.6004 - val_loss: 0.6045 - val_binary_crossentropy: 0.6045 - val_acc: 0.6047\n",
      "Epoch 11/2000\n",
      "39/39 [==============================] - 1s 28ms/step - loss: 0.5815 - binary_crossentropy: 0.5815 - acc: 0.6587 - val_loss: 0.5662 - val_binary_crossentropy: 0.5662 - val_acc: 0.6988\n",
      "Epoch 12/2000\n",
      " 8/39 [=====>........................] - ETA: 0s - loss: 0.5628 - binary_crossentropy: 0.5628 - acc: 0.7109"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 33>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     83\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_binary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2000\u001B[39m),\n\u001B[0;32m     84\u001B[0m              tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mModelCheckpoint(filepath\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheckpoints/ktree_orig_checkpoint\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     85\u001B[0m                                                 monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_binary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     88\u001B[0m                                                 save_weights_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     89\u001B[0m                                                 )]\n\u001B[0;32m     92\u001B[0m model, history[j, i, k, \u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m=\u001B[39m create_asymmetric_model(unique_pixels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_ds\u001B[38;5;241m.\u001B[39mimages[\u001B[38;5;241m0\u001B[39m]),\n\u001B[0;32m     93\u001B[0m                                                      use_bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, non_neg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     94\u001B[0m                                                      asymmetry_index\u001B[38;5;241m=\u001B[39masymmetry_index, learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate,\n\u001B[0;32m     95\u001B[0m                                                      layer_structure\u001B[38;5;241m=\u001B[39mtree_structure)\n\u001B[1;32m---> 97\u001B[0m fit_history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     98\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     99\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m print_fit_history(fit_history, epochs)\n\u001B[0;32m    101\u001B[0m model\u001B[38;5;241m.\u001B[39mload_weights(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcheckpoints/ktree_orig_checkpoint\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\keras\\engine\\training.py:1376\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1374\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_epoch_begin(epoch)\n\u001B[0;32m   1375\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[1;32m-> 1376\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n\u001B[0;32m   1377\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1378\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1379\u001B[0m         epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1380\u001B[0m         step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1381\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1382\u001B[0m         _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1383\u001B[0m       callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\keras\\engine\\data_adapter.py:1246\u001B[0m, in \u001B[0;36mDataHandler.steps\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1244\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data:  \u001B[38;5;66;03m# Set by `catch_stop_iteration`.\u001B[39;00m\n\u001B[0;32m   1245\u001B[0m   \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m-> 1246\u001B[0m original_spe \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m   1247\u001B[0m can_run_full_execution \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1248\u001B[0m     original_spe \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1249\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_steps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1250\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_steps \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m\n\u001B[0;32m   1251\u001B[0m     original_spe)\n\u001B[0;32m   1253\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m can_run_full_execution:\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:674\u001B[0m, in \u001B[0;36mBaseResourceVariable.numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnumpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    673\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 674\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    675\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    676\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy() is only available when eager execution is enabled.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:749\u001B[0m, in \u001B[0;36mBaseResourceVariable.read_value\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    740\u001B[0m \u001B[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001B[39;00m\n\u001B[0;32m    741\u001B[0m \n\u001B[0;32m    742\u001B[0m \u001B[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    746\u001B[0m \u001B[38;5;124;03m the read operation.\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    748\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRead\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 749\u001B[0m   value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_variable_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    750\u001B[0m \u001B[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001B[39;00m\n\u001B[0;32m    751\u001B[0m \u001B[38;5;66;03m# specifies instead of the device where the variable is.\u001B[39;00m\n\u001B[0;32m    752\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m array_ops\u001B[38;5;241m.\u001B[39midentity(value)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:728\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    726\u001B[0m       result \u001B[38;5;241m=\u001B[39m read_and_set_handle()\n\u001B[0;32m    727\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 728\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mread_and_set_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    730\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m    731\u001B[0m   \u001B[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001B[39;00m\n\u001B[0;32m    732\u001B[0m   \u001B[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001B[39;00m\n\u001B[0;32m    733\u001B[0m   tape\u001B[38;5;241m.\u001B[39mrecord_operation(\n\u001B[0;32m    734\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReadVariableOp\u001B[39m\u001B[38;5;124m\"\u001B[39m, [result], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle],\n\u001B[0;32m    735\u001B[0m       backward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x],\n\u001B[0;32m    736\u001B[0m       forward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x])\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:718\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001B[1;34m()\u001B[0m\n\u001B[0;32m    717\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_and_set_handle\u001B[39m():\n\u001B[1;32m--> 718\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mgen_resource_variable_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_variable_op\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    719\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    720\u001B[0m   _maybe_set_handle_data(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dtype, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, result)\n\u001B[0;32m    721\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:478\u001B[0m, in \u001B[0;36mread_variable_op\u001B[1;34m(resource, dtype, name)\u001B[0m\n\u001B[0;32m    476\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m    477\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 478\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mReadVariableOp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdtype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    480\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m    481\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#############\n",
    "### SETUP ###\n",
    "#############\n",
    "\n",
    "project_folder = ''\n",
    "bs = 256\n",
    "trials = 10\n",
    "epochs = 2000\n",
    "trees_set = [1]\n",
    "asymmetry_index = .2\n",
    "filename = project_folder + 'results/aktree_history_' + str(int(100 * asymmetry_index)) + '_testLearningRate.npy'\n",
    "classes = [[3, 5, 'mnist'],\n",
    "           [0, 6, 'fmnist'],\n",
    "           [14, 17, 'emnist'],\n",
    "           [2, 6, 'kmnist'],\n",
    "           [3, 5, 'cifar10'],\n",
    "           [5, 6, 'svhn'],\n",
    "           [3, 5, 'usps']]\n",
    "verbose = 1\n",
    "learning_rates = [.1, 1]\n",
    "\n",
    "#################\n",
    "### END SETUP ###\n",
    "#################\n",
    "\n",
    "if exists(filename) and input(\"Resume computation? (y/n)\") == 'y':\n",
    "    print(\"Recovering data...\")\n",
    "    history = np.load(filename, allow_pickle=True)\n",
    "else:\n",
    "    print(\"Results will be saved to:\", filename)\n",
    "    history = np.zeros((len(classes), trials, len(trees_set), 3))\n",
    "\n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "\n",
    "    # escludo i dataset a colori per il momento\n",
    "    if ds in ['cifar10', 'svhn']:\n",
    "        continue\n",
    "\n",
    "    print(f\"Dataset: {ds} / Pair: {t1}-{t2}\")\n",
    "\n",
    "    test_ds = ImageDataset(ds, 'test', data_dir=None)\n",
    "    train_ds = ImageDataset(ds, 'train', data_dir=None)\n",
    "\n",
    "    for x in [train_ds, test_ds]:\n",
    "        x.filter(t1, t2, overwrite=True)\n",
    "        x.shuffle()\n",
    "        x.normalize()\n",
    "        if x.images.shape[1:3] == (28, 28):\n",
    "            x.pad()\n",
    "        x.vectorize(True)\n",
    "\n",
    "    for k, trees in enumerate(trees_set):\n",
    "\n",
    "        print(f\"{trees}-tree\")\n",
    "\n",
    "        test_set = tf.data.Dataset.from_tensor_slices((test_ds.images, test_ds.labels)).map(\n",
    "            lambda x, y: (tf.tile(x, [trees]), y)).batch(bs)\n",
    "\n",
    "        for i in range(trials):\n",
    "\n",
    "            if history[j, i, k, 0] != 0:\n",
    "                continue\n",
    "\n",
    "            print(f\"Trial {i + 1}\")\n",
    "\n",
    "            with tf.device('/device:GPU:0'):\n",
    "\n",
    "                X_train, y_train, X_valid, y_valid = train_ds.bootstrap(.85, True)\n",
    "\n",
    "                train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(\n",
    "                    lambda x, y: (tf.tile(x, [trees]), y)).batch(bs)\n",
    "                valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid)).map(\n",
    "                    lambda x, y: (tf.tile(x, [trees]), y)).batch(bs)\n",
    "\n",
    "                tree_structure = create_asymmetric_tree_structure(len(train_ds.images[0]), .2)\n",
    "                tree_structure.reverse()\n",
    "                data1 = []\n",
    "\n",
    "                for learning_rate in learning_rates:\n",
    "\n",
    "                    for _ in range(2):\n",
    "\n",
    "                        callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=2000),\n",
    "                                     tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoints/ktree_orig_checkpoint\",\n",
    "                                                                        monitor='val_binary_crossentropy',\n",
    "                                                                        verbose=0,\n",
    "                                                                        save_best_only=True,\n",
    "                                                                        save_weights_only=True,\n",
    "                                                                        )]\n",
    "\n",
    "\n",
    "                        model, history[j, i, k, 2] = create_asymmetric_model(unique_pixels=len(train_ds.images[0]),\n",
    "                                                                             use_bias=False, non_neg=False,\n",
    "                                                                             asymmetry_index=asymmetry_index, learning_rate=learning_rate,\n",
    "                                                                             layer_structure=tree_structure)\n",
    "\n",
    "                        fit_history = model.fit(x=train_set, batch_size=bs, epochs=epochs,\n",
    "                                                validation_data=valid_set, validation_batch_size=bs,\n",
    "                                                callbacks=callbacks, verbose=verbose)\n",
    "                        print_fit_history(fit_history, epochs)\n",
    "                        model.load_weights('checkpoints/ktree_orig_checkpoint')\n",
    "\n",
    "                        evaluate_history = model.evaluate(x=test_set, batch_size=bs, verbose=0)\n",
    "                        print_evaluate_history(evaluate_history)\n",
    "\n",
    "                        history[j, i, k, 0:2] = evaluate_history[1:]\n",
    "                        data1.append(evaluate_history[2])\n",
    "\n",
    "                        #np.save(filename, history, allow_pickle=True)\n",
    "\n",
    "                        del model\n",
    "                        gc.collect()\n",
    "\n",
    "                print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}