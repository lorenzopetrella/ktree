{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "fcnn.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "mount_file_id": "1yPa4_TERRnpMOCLciJNiJVyLEDfyy26l",
   "authorship_tag": "ABX9TyOaOg470G1N56mzXs8ChE/z"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Set according to environment (e.g. local, Google Colab...)**"
   ],
   "metadata": {
    "id": "lFrTiHVXnp5S"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "project_folder = ''"
   ],
   "metadata": {
    "id": "R1TynGfJn9FM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1647888135726,
     "user_tz": -60,
     "elapsed": 4,
     "user": {
      "displayName": "Lorenzo Petrella",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15951970565465703880"
     }
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Body**"
   ],
   "metadata": {
    "id": "iZFxvzHy_pb6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from custom_libraries.image_dataset import *\n",
    "from custom_libraries.miscellaneous import *\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model(num_units):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(units=num_units, activation=None, kernel_initializer=tf.keras.initializers.HeNormal))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=.01))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE),\n",
    "                  metrics=['binary_crossentropy', 'acc'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "id": "GJEAI7dJBKGc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1647888140358,
     "user_tz": -60,
     "elapsed": 4,
     "user": {
      "displayName": "Lorenzo Petrella",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15951970565465703880"
     }
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "bs = 256\n",
    "trials = 10\n",
    "epochs = 2000\n",
    "trees_set = [1, 32]\n",
    "\n",
    "# classes = np.load(project_folder + 'results/classes.npy', allow_pickle=True)\n",
    "classes = [[3, 5, 'usps']]\n",
    "# TODO: verificare l'effetto di patience sul risultato di svhn (rischio underfitting)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=60, mode='min')\n",
    "\n",
    "history = np.zeros((len(classes), trials, len(trees_set), 2))\n",
    "#history = np.load(project_folder+'results/fcnn_history.npy', allow_pickle=True)\n",
    "\n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "\n",
    "    print(f\"Dataset: {ds} / Pair: {t1}-{t2}\")\n",
    "\n",
    "    #if history[j, 0, 0, 0] != 0:\n",
    "    #    continue\n",
    "\n",
    "    test_ds = ImageDataset(ds, 'test', data_dir=None, USPS_dir=project_folder + 'USPS/')\n",
    "    train_ds = ImageDataset(ds, 'train', data_dir=None, USPS_dir=project_folder + 'USPS/')\n",
    "\n",
    "    for x in [train_ds, test_ds]:\n",
    "        x.filter(t1, t2, overwrite=True)\n",
    "        x.shuffle()\n",
    "        x.normalize()\n",
    "        if x.images.shape[1:3] == (28, 28):\n",
    "            x.pad()\n",
    "        x.vectorize(True)\n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = train_ds.subset(shard=True, shard_number=trials, validation=True,\n",
    "                                                         validation_size=len(test_ds.images))\n",
    "    test_set = tf.data.Dataset.from_tensor_slices((test_ds.images, test_ds.labels)).batch(bs)\n",
    "\n",
    "    for k, trees in enumerate(trees_set):\n",
    "\n",
    "        print(f\"{trees}-FCNN\")\n",
    "\n",
    "        for i in range(trials):\n",
    "\n",
    "            if history[j, i, k, 0] != 0:\n",
    "                continue\n",
    "\n",
    "            print(f\"Trial {i + 1}\")\n",
    "\n",
    "            model = create_model(num_units=2 * trees)\n",
    "\n",
    "            train_set = tf.data.Dataset.from_tensor_slices((X_train[i], y_train[i])).batch(bs)\n",
    "            valid_set = tf.data.Dataset.from_tensor_slices((X_valid[i], y_valid[i])).batch(bs)\n",
    "\n",
    "            with tf.device('/device:GPU:0'):\n",
    "\n",
    "                fit_history = model.fit(x=train_set, batch_size=bs, epochs=epochs,\n",
    "                                        validation_data=valid_set, validation_batch_size=bs,\n",
    "                                        callbacks=[callback], verbose=0)\n",
    "                print_fit_history(fit_history, epochs)\n",
    "\n",
    "                evaluate_history = model.evaluate(x=test_set, batch_size=bs, verbose=0)\n",
    "                print_evaluate_history(evaluate_history)\n",
    "\n",
    "                history[j, i, k] = evaluate_history[1:]\n",
    "\n",
    "                np.save(project_folder + 'results/fcnn_history.npy', history,\n",
    "                        allow_pickle=True)"
   ],
   "metadata": {
    "id": "_p5yaGWI_rhQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1647890584560,
     "user_tz": -60,
     "elapsed": 2444205,
     "user": {
      "displayName": "Lorenzo Petrella",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15951970565465703880"
     }
    },
    "outputId": "70219fc4-624b-4bae-ee8d-729dac5ceda3"
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: usps / Pair: 3-5\n",
      "1-FCNN\n",
      "Trial 1\n",
      "Epochs: 622/2000 - Train BCE: 0.0282, accuracy: 100.0% - Validation BCE: 0.0918, accuracy: 96.97%\n",
      "Test BCE: 0.2943, accuracy: 88.34%\n",
      "Trial 2\n",
      "Epochs: 2000/2000 - Train BCE: 0.0739, accuracy: 98.88% - Validation BCE: 0.0498, accuracy: 100.0%\n",
      "Test BCE: 0.2754, accuracy: 90.8%\n",
      "Trial 3\n",
      "Epochs: 711/2000 - Train BCE: 0.0153, accuracy: 100.0% - Validation BCE: 0.1779, accuracy: 96.97%\n",
      "Test BCE: 0.3047, accuracy: 88.96%\n",
      "Trial 4\n",
      "Epochs: 607/2000 - Train BCE: 0.0236, accuracy: 100.0% - Validation BCE: 0.1144, accuracy: 90.91%\n",
      "Test BCE: 0.2245, accuracy: 92.02%\n",
      "Trial 5\n",
      "Epochs: 2000/2000 - Train BCE: 0.0211, accuracy: 100.0% - Validation BCE: 0.0569, accuracy: 96.97%\n",
      "Test BCE: 0.3154, accuracy: 88.96%\n",
      "Trial 6\n",
      "Epochs: 648/2000 - Train BCE: 0.1797, accuracy: 100.0% - Validation BCE: 0.2485, accuracy: 90.91%\n",
      "Test BCE: 0.3865, accuracy: 86.81%\n",
      "Trial 7\n",
      "Epochs: 2000/2000 - Train BCE: 0.0937, accuracy: 100.0% - Validation BCE: 0.214, accuracy: 93.75%\n",
      "Test BCE: 0.3395, accuracy: 91.41%\n",
      "Trial 8\n",
      "Epochs: 583/2000 - Train BCE: 0.0239, accuracy: 100.0% - Validation BCE: 0.1682, accuracy: 90.62%\n",
      "Test BCE: 0.2077, accuracy: 92.94%\n",
      "Trial 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [20]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     50\u001B[0m valid_set \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices((X_valid[i], y_valid[i]))\u001B[38;5;241m.\u001B[39mbatch(bs)\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/device:GPU:0\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m---> 54\u001B[0m     fit_history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m     print_fit_history(fit_history, epochs)\n\u001B[0;32m     59\u001B[0m     evaluate_history \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(x\u001B[38;5;241m=\u001B[39mtest_set, batch_size\u001B[38;5;241m=\u001B[39mbs, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\keras\\engine\\training.py:1420\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1407\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[0;32m   1408\u001B[0m       x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[0;32m   1409\u001B[0m       y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1418\u001B[0m       model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1419\u001B[0m       steps_per_execution\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution)\n\u001B[1;32m-> 1420\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1421\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1422\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1423\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1424\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1425\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1426\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1427\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1428\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1429\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1431\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1432\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m   1433\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\keras\\engine\\training.py:1710\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1708\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_test_counter\u001B[38;5;241m.\u001B[39massign(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m   1709\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_test_begin()\n\u001B[1;32m-> 1710\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, iterator \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39menumerate_epochs():  \u001B[38;5;66;03m# Single epoch.\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_metrics()\n\u001B[0;32m   1712\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\keras\\engine\\data_adapter.py:1196\u001B[0m, in \u001B[0;36mDataHandler.enumerate_epochs\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1194\u001B[0m   \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter\u001B[38;5;241m.\u001B[39mshould_recreate_iterator():\n\u001B[1;32m-> 1196\u001B[0m   data_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1197\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m epoch, data_iterator\n\u001B[0;32m   1198\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter\u001B[38;5;241m.\u001B[39mon_epoch_end()\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:486\u001B[0m, in \u001B[0;36mDatasetV2.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    484\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mor\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minside_function():\n\u001B[0;32m    485\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[1;32m--> 486\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43miterator_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOwnedIterator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    488\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.Dataset` only supports Python-style \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    489\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miteration in eager mode or within tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:755\u001B[0m, in \u001B[0;36mOwnedIterator.__init__\u001B[1;34m(self, dataset, components, element_spec)\u001B[0m\n\u001B[0;32m    751\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (components \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m element_spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    752\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    753\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    754\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot be specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 755\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    757\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_next_call_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:787\u001B[0m, in \u001B[0;36mOwnedIterator._create_iterator\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    782\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    783\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator_resource, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deleter \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    784\u001B[0m       gen_dataset_ops\u001B[38;5;241m.\u001B[39manonymous_iterator_v2(\n\u001B[0;32m    785\u001B[0m           output_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_types,\n\u001B[0;32m    786\u001B[0m           output_shapes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_shapes))\n\u001B[1;32m--> 787\u001B[0m   \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds_variant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    788\u001B[0m   \u001B[38;5;66;03m# Delete the resource when this object is deleted\u001B[39;00m\n\u001B[0;32m    789\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resource_deleter \u001B[38;5;241m=\u001B[39m IteratorResourceDeleter(\n\u001B[0;32m    790\u001B[0m       handle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator_resource,\n\u001B[0;32m    791\u001B[0m       deleter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deleter)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3314\u001B[0m, in \u001B[0;36mmake_iterator\u001B[1;34m(dataset, iterator, name)\u001B[0m\n\u001B[0;32m   3312\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   3313\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3314\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3315\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMakeIterator\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   3317\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "history = np.load(project_folder + 'results/fcnn_history.npy', allow_pickle=True)\n",
    "print(\"RESULTS:\")\n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "    print(f\"Dataset: {ds} / Pair: {t1}-{t2}\")\n",
    "    for k, trees in enumerate(trees_set):\n",
    "        print(f\"{k}-FCNN\")\n",
    "        print(f\"Accuracy: mean = {round(np.mean(history[j,:,k,1]), 4)}, standard deviation = {round(np.std(history[j,:,k,1]), 4)}\")"
   ],
   "metadata": {
    "id": "7St40wVIR06V",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1647890584562,
     "user_tz": -60,
     "elapsed": 23,
     "user": {
      "displayName": "Lorenzo Petrella",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15951970565465703880"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e7a3b1fc-ef07-4703-b3df-6f0f617c2b22"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}