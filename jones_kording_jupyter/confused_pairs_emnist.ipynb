{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from custompackage.load_data import *\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./data\\EMNIST\\raw\\gzip.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/561753746 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d46fa0e30a4e4cc5acd9e5f55444fe8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\EMNIST\\raw\\gzip.zip to ./data\\EMNIST\\raw\n",
      "emnist 0 10 11 0.8508771929824561\n",
      "emnist 1 10 11 0.8304093567251462\n",
      "emnist 2 10 11 0.8608187134502924\n",
      "emnist 3 10 11 0.8461988304093567\n",
      "emnist 4 10 11 0.8502923976608188\n",
      "emnist 5 10 11 0.8450292397660819\n",
      "emnist 6 10 11 0.8391812865497076\n",
      "emnist 7 10 11 0.8467836257309942\n",
      "emnist 8 10 11 0.8497076023391813\n",
      "emnist 9 10 11 0.8473684210526315\n",
      "emnist 0 10 12 0.9453766511960014\n",
      "emnist 1 10 12 0.9550160656908248\n",
      "emnist 2 10 12 0.952873973580864\n",
      "emnist 3 10 12 0.9432345590860407\n",
      "emnist 4 10 12 0.947161727954302\n",
      "emnist 5 10 12 0.9407354516244198\n",
      "emnist 6 10 12 0.9485897893609425\n",
      "emnist 7 10 12 0.9418064976794002\n",
      "emnist 8 10 12 0.9421635130310604\n",
      "emnist 9 10 12 0.9450196358443413\n",
      "emnist 0 10 13 0.9038565996740902\n",
      "emnist 1 10 13 0.9033134166214014\n",
      "emnist 2 10 13 0.8832156436719174\n",
      "emnist 3 10 13 0.8902770233568713\n",
      "emnist 4 10 13 0.9092884302009777\n",
      "emnist 5 10 13 0.9005975013579577\n",
      "emnist 6 10 13 0.888647474198805\n",
      "emnist 7 10 13 0.8832156436719174\n",
      "emnist 8 10 13 0.9076588810429115\n",
      "emnist 9 10 13 0.9016838674633352\n",
      "emnist 0 10 14 0.8855201254573968\n",
      "emnist 1 10 14 0.8541557762676425\n",
      "emnist 2 10 14 0.8782017773131208\n",
      "emnist 3 10 14 0.8609513852587559\n",
      "emnist 4 10 14 0.8923157344485102\n",
      "emnist 5 10 14 0.8891792995295348\n",
      "emnist 6 10 14 0.8808154730789336\n",
      "emnist 7 10 14 0.8933612127548354\n",
      "emnist 8 10 14 0.8782017773131208\n",
      "emnist 9 10 14 0.8792472556194459\n",
      "emnist 0 10 15 0.8980815347721822\n",
      "emnist 1 10 15 0.8992805755395683\n",
      "emnist 2 10 15 0.898880895283773\n",
      "emnist 3 10 15 0.8996802557953637\n",
      "emnist 4 10 15 0.903277378097522\n",
      "emnist 5 10 15 0.898880895283773\n",
      "emnist 6 10 15 0.9016786570743405\n",
      "emnist 7 10 15 0.9040767386091128\n",
      "emnist 8 10 15 0.8984812150279776\n",
      "emnist 9 10 15 0.9008792965627498\n",
      "emnist 0 10 16 0.7905897945659377\n",
      "emnist 1 10 16 0.7680583167660703\n",
      "emnist 2 10 16 0.8124585818422797\n",
      "emnist 3 10 16 0.8164347249834327\n",
      "emnist 4 10 16 0.8058316766070245\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t2 \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(t1 \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m+\u001B[39m classes):\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(trials):\n\u001B[0;32m     18\u001B[0m         \u001B[38;5;66;03m# Load the binary classification dataloaders\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m         trainloaders, validloaders, testloader \u001B[38;5;241m=\u001B[39m \u001B[43mdataset_weighted_split_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweighting\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m         \u001B[38;5;66;03m# Assign entirety of the datasets within each dataloader to a variable\u001B[39;00m\n\u001B[0;32m     22\u001B[0m         X_train \u001B[38;5;241m=\u001B[39m trainloaders[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mtensors[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mD:\\PC-LORENZO\\UNIVERSITA\\OneDrive - Politecnico di Milano\\III ANNO-Lorenzo\\2-CORSO PROGETTO\\ktree\\jones_kording_jupyter\\custompackage\\load_data.py:180\u001B[0m, in \u001B[0;36mdataset_weighted_split_all\u001B[1;34m(Batch_size, Target_class_1, Target_class_2, Data_weighting, Split, ds, permute, padded)\u001B[0m\n\u001B[0;32m    177\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;66;03m# Assign Binary Labels to target classes\u001B[39;00m\n\u001B[1;32m--> 180\u001B[0m Train_set \u001B[38;5;241m=\u001B[39m \u001B[43mformat_data_weighted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTarget_class_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTarget_class_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mData_weighting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mData_weighting\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpermute\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpermute\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadded\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadded\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    181\u001B[0m Test_set  \u001B[38;5;241m=\u001B[39m format_data_weighted(Test_set, Target_class_1, Target_class_2, Data_weighting\u001B[38;5;241m=\u001B[39mData_weighting, permute\u001B[38;5;241m=\u001B[39mpermute, padded\u001B[38;5;241m=\u001B[39mpadded)\n\u001B[0;32m    183\u001B[0m \u001B[38;5;66;03m# Set length for dataset splitting purposes\u001B[39;00m\n",
      "File \u001B[1;32mD:\\PC-LORENZO\\UNIVERSITA\\OneDrive - Politecnico di Milano\\III ANNO-Lorenzo\\2-CORSO PROGETTO\\ktree\\jones_kording_jupyter\\custompackage\\load_data.py:19\u001B[0m, in \u001B[0;36mformat_data_weighted\u001B[1;34m(Data_set, Target_class_1, Target_class_2, Data_weighting, permute, padded)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m Data_weighting \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpaired\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;66;03m# Load intire dataset with batch size equal to entire dataset\u001B[39;00m\n\u001B[0;32m     18\u001B[0m     Loader \u001B[38;5;241m=\u001B[39m DataLoader(Data_set, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(Data_set), shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 19\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, (inputs, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(Loader):\n\u001B[0;32m     20\u001B[0m         \u001B[38;5;66;03m# data and label_default contain entire dataset\u001B[39;00m\n\u001B[0;32m     21\u001B[0m         data \u001B[38;5;241m=\u001B[39m inputs\n\u001B[0;32m     22\u001B[0m         label_default \u001B[38;5;241m=\u001B[39m labels\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    520\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 521\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    524\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    525\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    559\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    560\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 561\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    562\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    563\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:127\u001B[0m, in \u001B[0;36mMNIST.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Any, Any]:\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;124;03m        index (int): Index\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001B[39;00m\n\u001B[0;32m    126\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 127\u001B[0m     img, target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata[index], \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtargets\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;66;03m# doing this so that it is consistent with all other datasets\u001B[39;00m\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;66;03m# to return a PIL Image\u001B[39;00m\n\u001B[0;32m    131\u001B[0m     img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img\u001B[38;5;241m.\u001B[39mnumpy(), mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "bs = 256\n",
    "weighting = 'paired'\n",
    "trials = 10\n",
    "ds_set = ['emnist']\n",
    "classes = 26\n",
    "\n",
    "# Initialize for record keeping\n",
    "paired_test = np.zeros((len(ds_set), trials, classes, classes))\n",
    "\n",
    "# For each 10-class dataset\n",
    "for k, ds in enumerate(ds_set):\n",
    "    # Go through each class\n",
    "    for t1 in range(10, 10 + classes):\n",
    "        # and pair it with every other class\n",
    "        for t2 in range(t1 + 1, 10 + classes):\n",
    "\n",
    "            for m in range(trials):\n",
    "                # Load the binary classification dataloaders\n",
    "                trainloaders, validloaders, testloader = dataset_weighted_split_all(bs, t1, t2, weighting, trials, ds)\n",
    "\n",
    "                # Assign entirety of the datasets within each dataloader to a variable\n",
    "                X_train = trainloaders[0].dataset.tensors[0]\n",
    "                y_train = trainloaders[0].dataset.tensors[1]\n",
    "                X_test = testloader.dataset.tensors[0]\n",
    "                y_test = testloader.dataset.tensors[1]\n",
    "\n",
    "                # initialize lda\n",
    "                lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "                # fit to images, labels\n",
    "                lda.fit(X_train, y_train)\n",
    "\n",
    "                # see accuracy for validation set\n",
    "                score_test = lda.score(X_test, y_test)\n",
    "\n",
    "                print(ds, m, t1, t2, score_test)\n",
    "\n",
    "                # record keeping\n",
    "\n",
    "                paired_test[k, m, t1 - 10, t2 - 10] = score_test\n",
    "\n",
    "                np.save('results/confused_pairs_emnist.npy', paired_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}