{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Google Colab compatibility\n",
    "project_folder = ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from custompackage.load_data import *\n",
    "from custompackage.load_architecture import *\n",
    "from custompackage.traintestloop import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5 mnist\n",
      "0 0 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 19>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28mprint\u001B[39m(j, i, k)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# Initialize the fcnn model, such that hidden layer is twice the number of trees\u001B[39;00m\n\u001B[1;32m---> 32\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43msimple_fcnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrees\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m#Train and test fcnn, assigning loss and acc values\u001B[39;00m\n\u001B[0;32m     34\u001B[0m loss_curve, acc_curve, loss[j,i,k], acc[j,i,k], model_t \u001B[38;5;241m=\u001B[39m train_test_fc(model, trainloaders[i],\n\u001B[0;32m     35\u001B[0m                                   validloaders[i], testloader, epochs\u001B[38;5;241m=\u001B[39mepochs)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:680\u001B[0m, in \u001B[0;36mModule.cuda\u001B[1;34m(self, device)\u001B[0m\n\u001B[0;32m    663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcuda\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, device: Optional[Union[\u001B[38;5;28mint\u001B[39m, device]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m    664\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001B[39;00m\n\u001B[0;32m    665\u001B[0m \n\u001B[0;32m    666\u001B[0m \u001B[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;124;03m        Module: self\u001B[39;00m\n\u001B[0;32m    679\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 680\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 570\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    573\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    574\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    575\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    580\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    581\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:593\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    590\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    592\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 593\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    594\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    595\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:680\u001B[0m, in \u001B[0;36mModule.cuda.<locals>.<lambda>\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcuda\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, device: Optional[Union[\u001B[38;5;28mint\u001B[39m, device]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m    664\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001B[39;00m\n\u001B[0;32m    665\u001B[0m \n\u001B[0;32m    666\u001B[0m \u001B[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;124;03m        Module: self\u001B[39;00m\n\u001B[0;32m    679\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 680\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply(\u001B[38;5;28;01mlambda\u001B[39;00m t: \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mc:\\pythonvenv\\lib\\site-packages\\torch\\cuda\\__init__.py:208\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    205\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    206\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 208\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    209\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    211\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "class_set = 0\n",
    "\n",
    "# Initialize settings\n",
    "bs = 256\n",
    "weighting = 'paired'\n",
    "trials = 10\n",
    "epochs = 2000\n",
    "trees_set = [1,32]\n",
    "\n",
    "# Load class-dataset list\n",
    "classes = np.load(project_folder + 'results/classes.npy', allow_pickle=True)\n",
    "\n",
    "# Initialize final test loss and accuracy variables\n",
    "loss = np.zeros((len(classes), trials, len(trees_set)))\n",
    "acc = np.zeros((len(classes), trials, len(trees_set)))\n",
    "\n",
    "\n",
    "# For each dataset enumerated from classes list\n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "    print(t1, t2, ds)\n",
    "    # Load data loaders\n",
    "    trainloaders, validloaders, testloader = dataset_weighted_split_all(bs, t1, t2, weighting, trials, ds, permute=False)\n",
    "    # Initialize input size for model initialization purposes\n",
    "    input_size = trainloaders[0].dataset.tensors[0][0].shape[0]\n",
    "    # For each trial\n",
    "    for k, trees in enumerate(trees_set):\n",
    "\n",
    "        # For every k-tree defined by trees_set\n",
    "        for i in range(trials):\n",
    "            print(j, i, k)\n",
    "            # Initialize the fcnn model, such that hidden layer is twice the number of trees\n",
    "            model = simple_fcnn(input_size, 2*trees, 1).cuda()\n",
    "            #Train and test fcnn, assigning loss and acc values\n",
    "            loss_curve, acc_curve, loss[j,i,k], acc[j,i,k], model_t = train_test_fc(model, trainloaders[i],\n",
    "                                              validloaders[i], testloader, epochs=epochs)\n",
    "\n",
    "            # Save accuracy and loss arrays\n",
    "            np.save(project_folder + 'results/fcnn_acc_'+str(class_set)+'.npy', acc)\n",
    "            np.save(project_folder + 'results/fcnn_loss_'+str(class_set)+'.npy', loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_set = 0\n",
    "acc = np.load(project_folder + 'results/fcnn_acc_'+str(class_set)+'.npy', allow_pickle=True)\n",
    "print(\"RESULTS:\")\n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "    print(f\"Dataset: {ds} / Pair: {t1}-{t2}\")\n",
    "    for k, trees in enumerate(trees_set):\n",
    "        print(f\"{k}-FCNN\")\n",
    "        print(f\"Accuracy: mean = {round(np.mean(acc[j,:,k]), 4)}, standard deviation = {round(np.std(acc[j,:,k]), 4)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}