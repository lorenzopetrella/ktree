{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Google Colab compatibility\n",
    "project_folder = ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from custompackage.load_data import *\n",
    "from custompackage.load_architecture import *\n",
    "from custompackage.traintestloop import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_set = 0\n",
    "\n",
    "# Initialize settings\n",
    "bs = 256\n",
    "weighting = 'paired'\n",
    "trials = 10\n",
    "epochs = 2000\n",
    "trees_set = [1,32]\n",
    "\n",
    "# Load class-dataset list\n",
    "classes = np.load(project_folder + 'results/classes.npy', allow_pickle=True)\n",
    "\n",
    "# Initialize final test loss and accuracy variables\n",
    "loss = np.zeros((len(classes), trials, len(trees_set)))\n",
    "acc = np.zeros((len(classes), trials, len(trees_set)))\n",
    "\n",
    "\n",
    "# For each dataset enumerated from classes list\n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "    print(t1, t2, ds)\n",
    "    # Load data loaders\n",
    "    trainloaders, validloaders, testloader = dataset_weighted_split_all(bs, t1, t2, weighting, trials, ds, permute=False)\n",
    "    # Initialize input size for model initialization purposes\n",
    "    input_size = trainloaders[0].dataset.tensors[0][0].shape[0]\n",
    "    # For each trial\n",
    "    for k, trees in enumerate(trees_set):\n",
    "\n",
    "        # For every k-tree defined by trees_set\n",
    "        for i in range(trials):\n",
    "            print(j, i, k)\n",
    "            # Initialize the fcnn model, such that hidden layer is twice the number of trees\n",
    "            model = simple_fcnn(input_size, 2*trees, 1).cuda()\n",
    "            #Train and test fcnn, assigning loss and acc values\n",
    "            loss_curve, acc_curve, loss[j,i,k], acc[j,i,k], model_t = train_test_fc(model, trainloaders[i],\n",
    "                                              validloaders[i], testloader, epochs=epochs)\n",
    "\n",
    "            # Save accuracy and loss arrays\n",
    "            np.save(project_folder + 'results/fcnn_acc_'+str(class_set)+'.npy', acc)\n",
    "            np.save(project_folder + 'results/fcnn_loss_'+str(class_set)+'.npy', loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_set = 0\n",
    "acc = np.load(project_folder + 'results/fcnn_acc_'+str(class_set)+'.npy', allow_pickle=True)\n",
    "print(\"RESULTS:\")\n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "    print(f\"Dataset: {ds} / Pair: {t1}-{t2}\")\n",
    "    for k, trees in enumerate(trees_set):\n",
    "        print(f\"{k}-FCNN\")\n",
    "        print(f\"Accuracy: mean = {round(np.mean(acc[j,:,k]), 4)}, standard deviation = {round(np.std(acc[j,:,k]), 4)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}