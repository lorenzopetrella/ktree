{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# change for Google Colab compatibility\n",
    "project_folder = ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Nostra implementazione**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from corso_progetto.custom_libraries.image_dataset import *\n",
    "from corso_progetto.custom_libraries.miscellaneous import *\n",
    "from jones_kording.custompackage.load_architecture import *\n",
    "from jones_kording.custompackage.traintestloop import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model(num_units):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(units=num_units, activation=None, kernel_initializer=tf.keras.initializers.HeNormal, ))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=.01))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=[tf.keras.losses.BinaryCrossentropy(name='binary_crossentropy'), 'acc'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bs = 256\n",
    "trials = 10\n",
    "epochs = 2000\n",
    "trees_set = [1, 32]\n",
    "\n",
    "classes = np.load(project_folder + 'results/classes.npy', allow_pickle=True)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=60)\n",
    "\n",
    "history = np.zeros(2, (len(classes), trials, len(trees_set)))\n",
    "\n",
    "loss = np.zeros((len(classes), trials, len(trees_set)))\n",
    "acc = np.zeros((len(classes), trials, len(trees_set)))\n",
    "\n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "\n",
    "    print(f\"Dataset: {ds} / Pair: {t1}-{t2}\")\n",
    "\n",
    "    #if history[j, 0, 0, 0] != 0:\n",
    "    #    continue\n",
    "\n",
    "    test_ds = ImageDataset(ds, 'test', data_dir=None, USPS_dir=project_folder + 'USPS/')\n",
    "    train_ds = ImageDataset(ds, 'train', data_dir=None, USPS_dir=project_folder + 'USPS/')\n",
    "\n",
    "    for x in [train_ds, test_ds]:\n",
    "        x.filter(t1, t2, overwrite=True)\n",
    "        x.shuffle()\n",
    "        x.normalize()\n",
    "        if x.images.shape[1:3] == (28, 28):\n",
    "            x.pad()\n",
    "        x.vectorize(True)\n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = train_ds.subset(shard=True, shard_number=trials, validation=True,\n",
    "                                                         validation_size=len(test_ds.images))\n",
    "    test_set = tf.data.Dataset.from_tensor_slices((test_ds.images, test_ds.labels)).batch(bs)\n",
    "\n",
    "    for k, trees in enumerate(trees_set):\n",
    "\n",
    "        print(f\"{trees}-FCNN\")\n",
    "\n",
    "        for i in range(trials):\n",
    "\n",
    "            if history[j, i, k, 0] != 0:\n",
    "                continue\n",
    "\n",
    "            print(f\"Trial {i + 1}\")\n",
    "\n",
    "            model = create_model(num_units=2 * trees)\n",
    "\n",
    "            train_set = tf.data.Dataset.from_tensor_slices((X_train[i], y_train[i])).batch(bs)\n",
    "            valid_set = tf.data.Dataset.from_tensor_slices((X_valid[i], y_valid[i])).batch(bs)\n",
    "\n",
    "            #with tf.device('/device:GPU:0'):\n",
    "\n",
    "            fit_history = model.fit(x=train_set, batch_size=bs, epochs=epochs,\n",
    "                                    validation_data=valid_set, validation_batch_size=bs,\n",
    "                                    callbacks=[callback], verbose=0)\n",
    "            print_fit_history(fit_history, epochs)\n",
    "\n",
    "            evaluate_history = model.evaluate(x=test_set, batch_size=bs, verbose=0)\n",
    "            print_evaluate_history(evaluate_history)\n",
    "\n",
    "            history[0, j, i, k] = evaluate_history[-1]\n",
    "\n",
    "            trainloader = [X_train[i], y_train[i], 0]\n",
    "            validloader = [X_valid[i], y_valid[i], 0]\n",
    "            testloader = [test_ds.images, test_ds.labels, 0]\n",
    "            model = simple_fcnn(test_ds.images.shape[1], 2 * trees, 1)\n",
    "            loss_curve, acc_curve, loss[j, i, k], acc[j, i, k], model_t = train_test_fc(model, trainloader,\n",
    "                                                                                        validloader, testloader,\n",
    "                                                                                        epochs=epochs)\n",
    "\n",
    "            history[1, j, i, k] = acc[j, i, k]\n",
    "\n",
    "            np.save(project_folder + 'method_comparison_results.npy', history,\n",
    "                    allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"RESULTS:\")\n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "    print(f\"Dataset: {ds} / Pair: {t1}-{t2}\")\n",
    "    for k, trees in enumerate(trees_set):\n",
    "        print(f\"{k}-FCNN\")\n",
    "        for i, method in [\"ours\", \"J&K\"]:\n",
    "            print(f\"Method: {method}\")\n",
    "            print(\n",
    "            f\"Accuracy: mean = {round(np.mean(history[i, j, :, k]), 4)}, standard deviation = {round(np.std(history[i, j, :, k]), 4)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}